# Отчет 

## Структура проекта
- build_and_test.sh -- скрипт для сборки пакета, прогона тестов и профилирования
- '*.с' и 'setup.py' -- исходный код пакета pysimd
- test.py -- тесты
- profile.py -- профилирование

## Результаты
![alt text](result.png?raw=true)
Удалось ускорить Python в 350 раз на 10 миллионах 
элементов массива и в 800 при 100 тысячах.

Чем обусловлен такая разница прироста 
производительности?

А я не знаю, честно говоря.
Предположения:
- Работа сборщика мусора после теста на 100'000 элементах
- Оптимизация for Python интерпретатором

Также получилось, что линейное сканирование циклом for проиграло simd теперь уже в 11 раз, по сравнению с 3.5 в прошлый раз. Возможно, тут тоже замешан сборщик мусора, судя по графикам.
